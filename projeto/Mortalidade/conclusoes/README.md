# Mortalidade â€” ConclusÃµes

## 1Âº Resultado

- `select(...)` exibe colunas **do fluxo ambulatorial** (`nome_procedimento`, `valor_procedimento`) mesmo sendo um pipeline de **mortalidade**.
- Registros de 2022 com `MUNICÃPIO FORA DE MG`.

**ConclusÃµes**
- **InconsistÃªncia de schema/seleÃ§Ã£o** (provÃ¡vel â€œcopiar-e-colarâ€ do ambulatorial): a amostra nÃ£o reflete as colunas especÃ­ficas de mortalidade (ex.: `qtde_Obitos`).
- PresenÃ§a de categoria **â€œfora do escopoâ€** (fora de MG) pode distorcer estatÃ­sticas municipais e eleva cardinalidade.


## 2Âº Resultado

- `df_agg` agrega por `(ano, nome_municipio, faixa_etaria, cid10)` e cria `prop_faixa_etaria = qtde_Obitos / total_ano`.
- `total_ano` Ã© somado **apenas por ano** (global), nÃ£o por municÃ­pio.

**ConclusÃµes**
- A proporÃ§Ã£o **nÃ£o captura estrutura etÃ¡ria local**: mistura todos os municÃ­pios do ano, diluindo o indicador e reduzindo sinal preditivo.
- Valores de proporÃ§Ã£o muito pequenos (na ordem de 1e-6) denunciam **denominador global**.


## 3Âº Resultado

- `prop_60plus` ~ 0.299â€¦ repetido em diferentes linhas, sugerindo **pouca variaÃ§Ã£o** por (ano, municÃ­pio) no exemplo mostrado.
- CÃ¡lculo de idosos via **`idade_media >= 60`** no nÃ­vel agregado.

**ConclusÃµes**
- Usar `idade_media >= 60` em agregados pode **subestimar/superestimar** a participaÃ§Ã£o idosa quando hÃ¡ mistura etÃ¡ria dentro do grupo.
- A pouca variaÃ§Ã£o indica que a feature pode estar **mal definida** para capturar heterogeneidade local.


## 4Âº Resultado

**ConclusÃµes**
- **Vazamento de alvo (target leakage)**: em `numeric_features` foi incluÃ­da **`qtde_Obitos`**, que Ã© a **prÃ³pria variÃ¡vel alvo**.  
  â†’ Explica o **RÂ² ~ 1** na Linear Regression e **infla** o desempenho de RF/GBT.
- AlÃ©m disso, `QTDE_OBITOS` Ã© uma variÃ¡vel **de contagem**; modelos e mÃ©tricas contÃ­nuas podem nÃ£o ser os mais adequados.


## 5Âº Resultado

- `nome_municipio_vec` domina (â‰ˆ 0.44); `cid10_vec` e `faixa_etaria_vec` com importÃ¢ncias menores; `qtde_Obitos` aparece com peso (>0), e `prop_60plus` Ã© muito baixo.

**ConclusÃµes**
- A presenÃ§a de **`qtde_Obitos` como feature** invalida a interpretaÃ§Ã£o das importÃ¢ncias (leakage).
- O vetor de nomes (`feature_names = assembler_inputs`) **nÃ£o expande one-hot**: dezenas/centenas de dummies sÃ£o **colapsadas** em um Ãºnico rÃ³tulo (ex.: `nome_municipio_vec`), criando **falsa dominÃ¢ncia**.



## ğŸ› ï¸ PrÃ³ximos Passos

### Dados e Limpeza
- [ ] Ajustar `df.select(...)` para **colunas de mortalidade** (remover campos do ambulatorial).
- [ ] Decidir tratamento para **â€œMUNICÃPIO FORA DE MGâ€** (excluir, OUTROS, ou segmentar anÃ¡lise).
- [ ] Normalizar nomes de municÃ­pios (acentos, casing, trims) e CIDs (mapeamento/agrupamento).

### Engenharia de VariÃ¡veis
- [ ] Recalcular `prop_faixa_etaria` **por (ano, nome_municipio)**:  
  `total_ano_mun = Î£ qtde_Obitos (ano, municÃ­pio)`  
  `prop_faixa_etaria_mun = qtde_Obitos / total_ano_mun`
- [ ] Recalcular `prop_60plus` **via faixas etÃ¡rias idosas** (60â€“69/70â€“79/80+) por **(ano, municÃ­pio)**.
- [ ] Considerar variÃ¡veis de **tendÃªncia e sazonalidade** (lags de Ã³bitos por municÃ­pio, mÃ©dias mÃ³veis, dummies sazonais).

### Modelagem e AvaliaÃ§Ã£o
- [ ] **Remover `qtde_Obitos` das features** (eliminar leakage).
- [ ] Trocar/experimentar com **GLM Poisson/NegBin** (link log) para contagens; ou **modelar `log1p(qtde_Obitos)`** com RF/GBT.
- [ ] **ValidaÃ§Ã£o temporal** (treino â‰¤ 2021/2022, teste > 2021/2022) e **backtesting** por mÃºltiplas janelas.
- [ ] Reportar **RMSE, MAE, MAPE** e, para Poisson/GLM, **deviance** e **pseudo-RÂ²**.

### ImportÃ¢ncia e Explicabilidade
- [ ] **Expandir nomes one-hot** e **agrupar importÃ¢ncias** por variÃ¡vel original.
- [ ] Calcular **Permutation Importance** no **teste** (pÃ³s-correÃ§Ãµes) e **parciais de dependÃªncia** para as top features.

---

## ğŸ”§ EsboÃ§o de correÃ§Ãµes (ideia de cÃ³digo)
```python
# --- ProporÃ§Ã£o por municÃ­pio ---
total_ano_mun = df_agg.groupBy("ano", "nome_municipio") \
    .agg(F.sum("qtde_Obitos").alias("total_ano_mun"))

df_agg = df_agg.join(total_ano_mun, ["ano", "nome_municipio"]) \
    .withColumn("prop_faixa_etaria_mun", F.col("qtde_Obitos") / F.col("total_ano_mun"))

# --- Idosos por faixas (nÃ£o por idade mÃ©dia) ---
faixas_idosas = ["60â€“69", "70â€“79", "80+"]  # ou consolidar em "60+"
idosos = (df_agg
    .filter(F.col("faixa_etaria").isin(faixas_idosas))
    .groupBy("ano", "nome_municipio")
    .agg(F.sum("qtde_Obitos").alias("qtde_60plus")))

total = df_agg.groupBy("ano", "nome_municipio") \
    .agg(F.sum("qtde_Obitos").alias("qtde_total"))

prop_idosos = idosos.join(total, ["ano", "nome_municipio"]) \
    .withColumn("prop_60plus", F.col("qtde_60plus") / F.col("qtde_total"))

df_ml = (df_agg
    .join(prop_idosos.select("ano", "nome_municipio", "prop_60plus"),
          ["ano", "nome_municipio"], "left")
    .fillna({"prop_60plus": 0}))

# --- Features sem leakage ---
categorical_features = ["nome_municipio", "faixa_etaria", "cid10"]
numeric_features = ["idade_media", "prop_faixa_etaria_mun", "prop_60plus"]  # (removido: qtde_Obitos)

# --- Modelos: opÃ§Ã£o 1 (GLM Poisson) ---
from pyspark.ml.regression import GeneralizedLinearRegression
glm = GeneralizedLinearRegression(family="poisson", link="log",
                                  labelCol="qtde_Obitos", featuresCol="features")
# montar pipeline com indexers/encoders + assembler (sem scaler)

# --- Modelos: opÃ§Ã£o 2 (RF/GBT em log-contagem) ---
# label_log = log1p(qtde_Obitos) -> treinar e avaliar revertendo com expm1 nas previsÃµes


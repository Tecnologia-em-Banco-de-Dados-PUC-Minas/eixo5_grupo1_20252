# üíªüìâ Machine Learning: Dados do SUS ü©∫üíä


Este reposit√≥rio documenta exclusivamente o **Machine Learning** aplicado √†s bases **Ambulatorial**, **Interna√ß√µes** e **Mortalidade**.  
A etapa de **ETL / feature engineering / dados** foi tratada anteriormente; aqui mantemos apenas os **artefatos de ML**:


- **C√≥digos** ‚Üí scripts de ML (treino, valida√ß√£o, compara√ß√£o)
- **M√©tricas** ‚Üí resultados (tabelas, gr√°ficos, relat√≥rios)
- **Conclus√µes** ‚Üí s√≠ntese das descobertas e decis√µes



No final, voc√™ encontrar√° um **guia r√°pido dos principais algoritmos de aprendizado de m√°quina** utilizados, a indicar o que se espera de cada um e os valores a partir dos quais podem ser considerados satisfat√≥rios ou insatisfat√≥rios.

---

## üìö Sum√°rio ‚Äî Artefatos de ML

- [C√≥digos](#sum-codigos)
- [M√©tricas](#sum-metricas)
- [Conclus√µes](#sum-conclusoes)

---

Cada base cont√©m **tr√™s artefatos**; ao clicar, ser√° direcionado √† op√ß√£o selecionada.


| Base | C√≥digos | M√©tricas | Conclus√µes |
|---|---|---|---|
| **Ambulatorial** |[`Ambulatorial/codigos/`](./Ambulatorial/codigos/) | [`Ambulatorial/metricas/`](./Ambulatorial/metricas/) | [`Ambulatorial/conclusoes/`](./Ambulatorial/conclusoes/) |
| **Interna√ß√µes** |[`Internacoes/codigos/`](./Internacoes/codigos/) | [`Internacoes/metricas/`](./Internacoes/metricas/) | [`Internacoes/conclusoes/`](./Internacoes/conclusoes/) |
| **Mortalidade** |[`Mortalidade/codigos/`](./Mortalidade/codigos/) | [`Mortalidade/metricas/`](./Mortalidade/metricas/) | [`Mortalidade/conclusoes/`](./Mortalidade/conclusoes/) |


---

## üìä Organiza√ß√£o por Base de Dados


**Ambulatorial**  
- **C√≥digos:** [`Ambulatorial/codigos/`](./Ambulatorial/codigos/)  
- **M√©tricas:** [`Ambulatorial/metricas/`](./Ambulatorial/metricas/)  
- **Conclus√µes:** [`Ambulatorial/conclusoes/`](./Ambulatorial/conclusoes/)


**Interna√ß√µes**  
- **C√≥digos:** [`Internacoes/codigos/`](./Internacoes/codigos/)  
- **M√©tricas:** [`Internacoes/metricas/`](./Internacoes/metricas/)  
- **Conclus√µes:** [`Internacoes/conclusoes/`](./Internacoes/conclusoes/)


**Mortalidade**   
- **C√≥digos:** [`Mortalidade/codigos/`](./Mortalidade/codigos/)  
- **M√©tricas:** [`Mortalidade/metricas/`](./Mortalidade/metricas/)  
- **Conclus√µes:** [`Mortalidade/conclusoes/`](./Mortalidade/conclusoes/)



-----

# üíª Guia R√°pido de Modelos de Machine Learning


> **Resumo ‚Äî modelos, intuito e o que esperar**
Este guia organiza as principais **fam√≠lias de modelos de ML** para voc√™ escolher r√°pido o candidato certo e julgar a qualidade sem mist√©rio. A ideia √© pr√°tica: cada fam√≠lia traz **quando usar**, **m√©tricas ideais** e **regras de bolso** (limiares t√≠picos) para saber se o resultado est√° **bom** ou **ruim**, sempre a comparar com um **baseline** simples.

**üîç Fam√≠lias e intuito**
- **Classifica√ß√£o**: prever r√≥tulos (sim/n√£o, multi-classes). √ötil para cr√©dito, churn, fraude.  
- **Regress√£o**: prever n√∫meros cont√≠nuos (pre√ßo, demanda).  
- **N√£o supervisionado**: explorar estrutura (clusters) e reduzir dimens√£o para visualizar/limpar ru√≠do.  
- **Recomenda√ß√£o**: ordenar itens relevantes (top-K) para cada usu√°rio.  
- **S√©ries temporais**: prever valores ao longo do tempo respeitando sazonalidade/tend√™ncia.  
- **Detec√ß√£o de Anomalia**: achar casos raros/at√≠picos com m√≠nimo alarme falso.

**üîç Ao abrir cada se√ß√£o, voc√™ ver√°:**
- **Quando usar**: em que tipos de dados/problemas o modelo brilha.
- **M√©tricas certas**: o que medir para n√£o se enganar (ex.: AUPRC em dados desbalanceados).
- **Regras de bolso**: valores de refer√™ncia (ex.: AUC > 0.75 ‚Äúbom‚Äù) para um primeiro crivo.
- **Sinais de alerta**: dicas r√°pidas de overfit, underfit ou *tuning* mal feito.
- **Nota de dom√≠nio**: lembre-se de ajustar *thresholds* conforme o **custo do erro** (FP vs. FN) no seu caso real.

## üì¢Fam√≠lias ##


<details>
  <summary><strong>Classifica√ß√£o</strong></summary>

Regress√£o Log√≠stica
- **Uso**: classes bin√°rias; baseline forte e interpret√°vel.  
- **M√©tricas**: AUC-ROC, AUPRC (desbalanceado), F1, Log-loss, Brier.  
- **Regras de bolso**:  
  - AUC ‚âà 0.5 (aleat√≥rio) ‚Ä¢ **> 0.75 bom** ‚Ä¢ **> 0.85 √≥timo**  
  - AUPRC baseline = **preval√™ncia**; **‚â• 3√ó** a preval√™ncia = bom  
  - Brier **< 0.1** = boa calibra√ß√£o

√Årvore de Decis√£o
- **Uso**: interpret√°vel com n√£o linearidades; baseline tabular.  
- **M√©tricas**: AUC, F1, Accuracy.  
- **Regras**: √∫til se chega **perto** de RF/GBM com explica√ß√µes claras.

Random Forest
- **Uso**: tabulares com muitos sinais/outliers.  
- **M√©tricas**: AUC, F1, Accuracy, OOB score.  
- **Regras**: espere **+2‚Äì10 p.p. de AUC** vs. regress√£o/√°rvore simples.

Gradient Boosting (XGBoost/LightGBM/CatBoost)
- **Uso**: SOTA em dados tabulares.  
- **M√©tricas**: AUC, F1, Log-loss.  
- **Regras**: **supera RF** na maioria; se **AUC < RF**, revise tuning/overfit.

SVM (Classifica√ß√£o)
- **Uso**: margens m√°ximas; kernels p/ fronteiras complexas; datasets m√©dios.  
- **M√©tricas**: AUC, F1.  
- **Regras**: com RBF, **AUC ‚â• 0.80** em problemas bem definidos.

k-NN (Classifica√ß√£o)
- **Uso**: baseline n√£o-param√©trico; requer escala.  
- **M√©tricas**: Accuracy, F1.  
- **Regras**: se **n√£o supera** regress√£o/√°rvore, faltam features ou h√° alto vi√©s.

Naive Bayes
- **Uso**: texto/contagens; muito r√°pido.  
- **M√©tricas**: F1, AUC.  
- **Regras**: em bag-of-words, **F1 competitivo**; fora disso, perde para GBM/SVM.

Redes Neurais (MLP, CNN, RNN/Transformers)
- **Uso**: imagem/√°udio/texto (CNN/Transformers); tabulares com muito dado (MLP).  
- **M√©tricas**: Accuracy, F1, AUC (depende).  
- **Regras**:  
  - **Imagem (CNN)**: accuracy **> 90%** comum em datasets limpos  
  - **Texto (Transformers)**: F1 **> 0.85** em intent/NER bem definidos  
  - Em tabulares, s√≥ valem se **superarem GBM**

</details>


<details>
  <summary><strong>Regress√£o</strong></summary>

Linear / Ridge / Lasso
- **Uso**: baseline interpret√°vel.  
- **M√©tricas**: RMSE, MAE, R¬≤, MAPE.  
- **Regras**:  
  - **R¬≤ > 0.7** bom ‚Ä¢ **> 0.9** √≥timo (se problema previs√≠vel)  
  - **RMSE ‚â§ 0.8√ó œÉ(y)** √© bom  
  - **MAPE < 10%** muito bom ‚Ä¢ **10‚Äì20%** razo√°vel

√Årvores / Random Forest / GBM (Regress√£o)
- **Uso**: n√£o linearidades/intera√ß√µes.  
- **M√©tricas**: RMSE, MAE, R¬≤.  
- **Regras**: devem **bater o linear**; se n√£o, falta feature engineering/tuning.

SVR / k-NN (Regress√£o)
- **M√©tricas**: MAE, RMSE, R¬≤.  
- **Regras**: em datasets menores, esperar **R¬≤ ‚â• 0.7** quando bem comportado.

</details>


<details>
  <summary><strong>N√£o Supervisionado</strong></summary>

K-Means
- **Uso**: clusters ‚Äúesf√©ricos‚Äù; padronizar dados.  
- **M√©tricas**: Silhouette, Calinski-Harabasz, Davies‚ÄìBouldin.  
- **Regras**: **Silhouette > 0.5** bom ‚Ä¢ **> 0.7** √≥timo; **DB < 0.5** bom.

DBSCAN
- **Uso**: clusters de forma arbitr√°ria + ru√≠do.  
- **M√©tricas**: Silhouette; % de ru√≠do.  
- **Regras**: se **ru√≠do > 30‚Äì40%**, ajuste `eps/minPts`.

Hier√°rquico
- **Uso**: dendrogramas; granularidade vari√°vel.  
- **M√©tricas**: Silhouette/CH/DB.  
- **Regras**: buscar ‚Äújoelhos‚Äù claros no dendrograma.

Redu√ß√£o de Dimens√£o (PCA, t-SNE, UMAP)
- **Uso**: compress√£o/visualiza√ß√£o/ru√≠do.  
- **M√©trica (PCA)**: vari√¢ncia explicada.  
- **Regras**: **2‚Äì3 PCs > 70%** j√° ajuda; t-SNE/UMAP avalie separabilidade **visual** (n√£o √© m√©trica global).

</details>


<details>
  <summary><strong>Recomenda√ß√£o</strong></summary>

Colaborativo (MF/ALS) & Conte√∫do
- **M√©tricas**: Precision@K, Recall@K, MAP/NDCG@K, cobertura/diversidade.  
- **Regras**:  
  - **Precision@10 ‚â• 0.30** (consumer)  
  - **NDCG@10 ‚â• 0.60** indica ranking √∫til  
  - Compare com baseline ‚Äú**mais populares**‚Äù

</details>


<details>
  <summary><strong>S√©ries Temporais</strong></summary>

ARIMA / ETS / Prophet
- **M√©tricas**: MAPE, sMAPE, RMSE (holdout/rolling).  
- **Regras**: **MAPE < 10%** √≥timo ‚Ä¢ **10‚Äì20%** aceit√°vel; use **valida√ß√£o temporal**.

GBM/LSTM/Transformers (Time Series)
- **M√©tricas**: idem acima.  
- **Regras**: **superar Naive/Seasonal Naive**; caso contr√°rio, overfit/tuning.

</details>


<details>
  <summary><strong>Detec√ß√£o de Anomalias</strong></summary>

Isolation Forest / One-Class SVM / Autoencoders
- **M√©tricas**: Precision@K, AUROC/AUPRC (se houver r√≥tulos), FPR.  
- **Regras**: **AUPRC ‚â• 3‚Äì5√ó preval√™ncia**; manter **FPR < 1‚Äì5%** quando custo de FP √© alto.

</details>



## üí° Dicas Pr√°ticas

- **Sempre compare com baseline**:  
  - Classifica√ß√£o: AUC baseline = 0.5; **AUPRC baseline = preval√™ncia**  
  - Regress√£o: compare RMSE/MAE com **œÉ(y)** e com modelo ing√™nuo (m√©dia/√∫ltimo valor)
- **Valida√ß√£o correta**: k-fold estratificado (i.i.d.) ou **valida√ß√£o temporal** (s√©ries)  
- **Signific√¢ncia**: diferen√ßas **< 1‚Äì2 p.p.** podem n√£o ser estatisticamente relevantes  
- **Calibra√ß√£o**: use **Brier** e curvas de calibra√ß√£o quando a probabilidade vira decis√£o  
- **Custo do erro**: ajuste **threshold** p/ otimizar **precis√£o/recall** conforme impacto de FP/FN

------

<details>
  <summary><strong>Gloss√°rio r√°pido de m√©tricas</strong></summary>

- **AUC-ROC**: prob. de ranquear positivo acima do negativo (0.5 = aleat√≥rio).  
- **AUPRC**: √°rea sob precis√£o √ó recall; baseline = preval√™ncia.  
- **F1**: m√©dia harm√¥nica entre precis√£o e recall.  
- **Log-loss**: penaliza probabilidades erradas; menor √© melhor.  
- **Brier**: erro quadr√°tico de probabilidade; < 0.1 sugere boa calibra√ß√£o.  
- **Accuracy**: % de acertos; fr√°gil com desbalanceamento.  
- **RMSE/MAE**: erro m√©dio (quadr√°tico/absoluto) na regress√£o.  
- **R¬≤**: propor√ß√£o da vari√¢ncia explicada (0‚Äì1).  
- **MAPE/sMAPE**: erro percentual (absorve escala).  
- **Silhouette**: coes√£o √ó separa√ß√£o de clusters (-1‚Äì1).  
- **Calinski-Harabasz / Davies‚ÄìBouldin**: √≠ndices de qualidade de cluster (maior/melhor e menor/melhor, respectivamente).  
- **Precision@K / Recall@K / NDCG@K**: m√©tricas de ranking/top-K em recomenda√ß√£o.  

</details>



